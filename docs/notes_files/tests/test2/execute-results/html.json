{
  "hash": "604f3ee0ad85b3657322e4557dfda856",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"STA 9890 - Spring 2025 </br> Test 2: Classification and Ensemble Methods\"\n---\n\n\n\nThe original test booklet can be found [here](./STA9890_test2_2025-Spring.pdf). \n$$\\newcommand{\\bX}{\\mathbf{X}}\\newcommand{\\by}{\\mathbf{y}}\\newcommand{\\bx}{\\mathbf{x}}\\newcommand{\\R}{\\mathbb{R}}\\newcommand{\\bbeta}{\\mathbf{\\beta}}\\newcommand{\\argmin}{\\text{arg min}}\\newcommand{\\bD}{\\mathbf{D}}\\newcommand{\\bzero}{\\mathbf{0}}\\newcommand{\\bI}{\\mathbf{I}}\\newcommand{\\bz}{\\mathbf{z}} \\newcommand{\\P}{\\mathbb{P}}$$ \n\n## Multiple Choice (30 points - 10 questions at 3 points each)\n\n1. In classification, a *false negative* refers to an observation which is\n   in the negative (0) class, but is falsely predicted as a positive (1) instead.\n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   **False** - this is a *false positive*. \n   Because we predict a *positive* label, this scenario describes a *positive*;\n   because our prediction is wrong, this scenario describes a *positive*. \n   \n   :::\n\n2. *Boosting* is the practice of building an ensemble by sub-sampling features.\n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   **False**. Boosting is iterative refinement of a predictor (see below). \n   Feature sub-sampling does not have a universal name, though it is sometimes\n   called the *random subspace* method.\n   \n   :::\n   \n3. Under a suitable generative model, logistic regression is BLUE. \n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   **False**. Logistic regression is not a linear estimator (hence the need\n   for iterative solvers) nor is it unbiased. To wit, \n   \n\n\n   ::: {.cell}\n   \n   ```{.r .cell-code}\n   beta <- c(1, 2, 3)\n   \n   rowMeans(replicate(5000, {\n    \n    X <- matrix(rnorm(50 * 3), nrow=50)\n    eta <- X %*% beta\n    mu <- 1/(1+exp(-eta))\n    y <- rbinom(50, size=1, prob=mu)\n   \n    coef(glm(y ~ X + 0, family=binomial))\n   }))\n   ```\n   \n   ::: {.cell-output .cell-output-stdout}\n   \n   ```\n          X1        X2        X3 \n    3.889216  8.126925 12.109190 \n   ```\n   \n   \n   :::\n   :::\n\n\n   \n   :::\n   \n4. Poisson or log-linear regression is suitable for predicting count-valued\n   responses, such as the number of goals scored in a soccer match. \n    \n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   **True**. Poisson random variables are often used to model small counts,\n   such as the number of goals scored, and so log-linear regression is a good\n   choice. Note, however, that the *margin of victory* (the difference in\n   scores) does not follow a Poisson distribution (since it can be negative\n   if the other team wins) and a *Skellam* distribution must be used instead.\n   \n   :::\n   \n5. Which of the following are properties of support vector classifiers? \n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   - Use of Hinge Loss ✅\n   - Automatic Identification of Kernel Points❓\n   - Lack of Tuning Parameters\n   - Probabilistic Output\n   - Insensitivity to training data far from the margin ✅\n   \n   *Note: \"Kernel Points\" is not, in my experience, a\n   standard terminology, but I will allow either answer\n   here for full credit.*\n   \n   :::\n   \n6. Which of the following are discriminative classifiers? \n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   - LDA \n   - SVM ✅\n   - Random Forest ✅\n   - Decision Trees ✅\n   - Boosting\n   - QDA\n   - Bayes' Rule\n   \n   :::\n   \n7. A maximum likelihood estimator is one which sets the unknown parameters in\n   order to maximize the negative log PDF/PMF of the sampling distribution on\n   the observed data. \n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   **False**. The _maximum_ likelihood estimator is obtained by _maximizing_\n   the likelihood or equivalently _minimizing_ the _negative_ logarithm of\n   the likelihood. \n   \n   :::\n   \n8. Multiple Choice: Which of the following **ARE NOT** convex\n   approximations to 0/1 Accuracy loss in classification?\n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   - Hinge Loss\n   - Smoothed Hinge Loss\n   - Gini Coefficient ✅\n   - False Negative Rate ✅\n   - Binomial Deviance Loss \n   - Tree Loss ✅\n   \n   :::\n   \n9. The main purpose of *boosting* is to iteratively refine our \n   predictor by compensating for previous prediction errors. \n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   **True**. \n   \n   :::\n   \n10. We cannot use cross-validation to tune the regularization parameter  \n    ($\\lambda$) of logistic ridge regression for maximum 0/1-Accuracy because\n    the 0/1-Accuracy loss function is nonconvex.\n\n    ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n    **False**. We can use CV to optimize accuracy. Convexity comes in to play\n    in the *tuning* procedure (because it requires search over a\n    high-dimensional parameter space) and typically requires us to use a\n    surrogate loss. \n   \n    :::\n\n## Short Answer (40 points - 8 questions at 5 points each)\n\n1. Apple devices support `FaceID` as an alternative to traditional\n   password-based authentication. (In this context a 'positive' refers to an\n   authorized user.) Label each of the following scenarios as a false positive\n   (FP), false negative (FN), true positive (TP), or true negative (TN).\n   \n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n\n   - **TP**: I am able to successfully authenticate on my phone.\n   - **FN**: My phone refuses to authenticate me because I just woke \n     up and my hair is a mess (`bed head').\n   - **FP**: My phone is stolen by my evil twin who is then able to access it\n     because his face matches mine.\n   - **TN**: My phone cannot be accessed by my kids when they take it\n     without permission.\n   - **TP**: My wife is added as a second user profile on my phone and \n   she is able to use it to check my emails for me while I am driving.\n\n   :::\n\n2. Given a binary classifier, how can you use it to perform to multi-class\n   classification? *(Hint: \"One- vs-rest\" approaches may be easier to describe.)*\n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   See [`sklearn` docs](https://scikit-learn.org/stable/modules/multiclass.html#ovr-classification). \n   \n   Things to mention include (but aren't limited to): \n   \n   - Training $K$ different classifiers, each using the whole data set\n     - Repeatedly changing the target variable to an indicator for a single class\n   - Prediction by taking the 'most likely' class\n   - A bit more interpretable\n   - A bit faster than alternatives\n\n   :::\n\n3. Compare and contrast *bagging* and *stacking*. Give at least 2\n   similarities and two differences.\n\n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   Possible similarities include: \n   \n   - Ensemble learning\n   - Can use arbitrary base learners\n   - Parallelizable\n   - Aim for variance reduction, not bias mitigation\n   \n   Possible differences include: \n   \n   - Stacking uses *different* base learners, while bagging *reuses* one family\n   - Bagging has resampling involved\n   - Stacking requires fitting a second set of weights, and hence an additional\n     data split\n\n   :::\n\n4. Describe the three parts of a *generalized linear model*, noting\n   their general role in GLM specification and precisely identifying in\n   logistic regression:\n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   The parts of a GLM are: \n   \n   1. The linear predictor\n      - Purpose: Estimates (a transform of) the conditional mean using a linear\n                 combination of features. Can be replaced by splines or kernel\n                 if appropriate to the problem.\n      - Logistic Regression: Standard ($\\bX\\bbeta$)\n   2. The sampling distribution\n      - Purpose: Generative model for the observed $y_i$. Varied to make data\n        type fit distribution\n      - Logistic Regression: Bernoulli\n   3. Mapping (or inverse link)\n      - Purpose: Maps the domain of the linear predictor ($\\R$) to a suitable\n        set of values that can be the mean of the sampling distribution\n      - Logistic Regression: $f(z) = 1/(1+e^{-z}) = e^z/(1+e^z) = \\text{softmax}(1, z)$\n        which is known as the *logistic* function\n\n   :::\n\n5. Given the following data, draw the decision boundary estimated by a\n   maximum margin classifier and mark the support points by circling them.\n   \n\n\n   ::: {.cell}\n   ::: {.cell-output-display}\n   ![](test2_files/figure-html/unnamed-chunk-2-1.png){width=672}\n   :::\n   :::\n\n\n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   Something like this: \n   \n\n\n   ::: {.cell}\n   ::: {.cell-output-display}\n   ![](test2_files/figure-html/unnamed-chunk-3-1.png){width=672}\n   :::\n   :::\n\n\n   \n   :::\n\n6. Given the following set of classification outcomes, compute the \n   Folwkes-Mallows (FM) Index:\n  \n\n\n   ```{=html}\n<table>\n    <tr>\n        <td></td>\n        <td></td>\n        <td colspan=\"2\">Ground Truth</td>\n    </tr>\n    <tr>\n        <td></td>\n        <td></td>\n        <td>+</td>\n        <td>-</td>\n    </tr>\n    <tr>\n        <td rowspan=\"2\"></br>Prediction</td><td>+</td><td>50</td><td>10</td>\n    </tr>\n    <tr>\n        <td></td><td>-</td><td>10</td><td>1000</td>\n    </tr>\n</table>\n\n   ```\n\n\n   \n   Recall that\n   $$\\text{FM} = \\sqrt{\\text{PPV} \\times \\text{TPR}} \n   \\text{ where } \\text{PPV} = 1 - \\text{FDR} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} \n   \\text{ and } \\text{TPR} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$$\n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   We have \n   \n   $$\\text{PPV} = \\frac{50}{50+10} = \\frac{5}{6}$$\n   \n   and \n   \n   $$\\text{TPR} = \\frac{50}{50+10} = \\frac{5}{6}$$\n   \n   so\n   \n   $$\\text{FM} = \\sqrt{\\frac{5}{6} * \\frac{5}{6}} = \\frac{5}{6}$$\n   :::\n\n7. Give an example of an *ordinal* classification problem and explain\n   *in a concrete problem-specific sense* why it cannot be approached as\n   a binary or multiclass classification problem (*i.e.*, your answer needs\n   to be more substantial than \"because it is ordinal.\").\n\n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   Many possible solutions. Key things to highlight are ordered, but non-numeric,\n   categories (e.g., user ratings or survey responses). Non-additivity of response.\n\n   :::\n\n8. Compare and contrast *Naive Bayes* and *Quadratic Discriminant\n   Analysis*. Give at least 2 similarities and two differences.\n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   Possible Similarities: \n   \n   - Generative classifiers\n   - Based on multivariate normal distribution\n   - Both require estimating class means\n   \n   Possible Differences: \n   \n   - NB is better for high-dim, QDA for low-dim\n   - NB has a linear decision boundary (linear method) while QDA has a parabolic\n     boundary\n   - Difference covariance assumptions\n\n   :::\n\n## Mathematics of Machine Learning (30 points total)\n\nIn this section, you will develop your own *multinomial generative\nclassifier* to determine whether a given email is valid (\"ham\") or spam.\n\nBefore we get into the mathematics, recall that a *multinomial*\ndistribution is a generalization of the binomial distribution (with a\ncategorical sampling scheme replacing the Bernoulli). Specifically, a\n$K$-class multinomial is characterized by a sample size $n \\in \\mathbb{N}$\nand a probability vector $\\mathbf{p}=(p_1, p_2, \\dots p_K)$ where\n$\\sum_i p_i = 1$ and all $p_i \\geq 0$.  The PMF of an observation is \nthen given by\n$$\\mathbb{P}(\\mathbf{X} = \\mathbf{x}) = \\mathbb{P}(X_1 = x_1, X_2 = x_2, \\dots, X_K=x_K) = \\frac{n!}{x_1!x_2!\\dots x_K!}p_1^{x_1}p_2^{x_2}\\dots p_K^{x_K}$$\nwhere $(x_1, x_2, \\dots, x_K)$ are the number of observations in each category.\n\nFor example, if a $3$-class multinomial has probability parameters\n$(0.5, 0.25, 0.25)$ and we observe $(3, 1, 1)$, the PMF of that observation is:\n$$\\frac{5!}{3!1!1!}0.5^30.25^10.25^1 = \\frac{120}{6 * 1 * 1}(0.125)(0.25)(0.25) = 0.15625.$$\n\nYou want to use a multinomial generative classifier to distinguish emails based\non certain words. After discussion with your IT department, you have collected\na series of valid and spam emails and found that they contain the following\nword counts:\n\n::: #count-tbl\n\n| Word       | Valid | Spam |\n|:----------:|------:|-----:|\n| Deal       | 20    | 80   |\n| Double     | 10    | 100  |\n| Money      | 80    | 100  |\n| Free       | 20    | 100  |\n| Spreadsheet| 20    | 5    |\n| Revenue    | 40    | 12   |\n| Classifier | 10    | 3    |\n\n:::\n\n(Emails may contain other words, but you do not include them in your model.)\n\nIn this context, we are using a *bag of words* approach, where the only\nthing that matters is the counts of various words, not the order in which they\nappear or any other words not on our list.\n\nYou also know that your company's domain receives nine times as many spam\nmessages as valid ones.\n\n1. Given the above information, what should your *prior* probabilities\n   be for $\\P(\\text{Valid})$ and $\\P(\\text{Spam}) = 1 - \\P(\\text{Valid})$?\n   (3 points) \n   \n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n\n   We can simply read the priors off the given information: \n\n   $$\\P(\\text{Spam}) = 9\\P(\\text{Valid}) \\implies \\P(\\text{Valid}) + \n     \\P(\\text{Spam}) = \\P(\\text{Valid}) + 9 * \\P(\\text{Valid}) = 1 \n     \\implies 10\\P(\\text{Valid}) = 1$$ giving us: \n\n   - $\\P(\\text{Valid}) = 10\\%$\n   - $\\P(\\text{Spam}) = 1 - \\P(\\text{Valid}) = 90\\%$\n\n   :::\n      \n2. Using the above text, what are the $\\mathbf{p}$ probabilities for\n   both classes? Write your answer as two probability vectors. (5 points)\n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n\n   Keeping the same order of words in the above example, we build the probability\n   vectors by aggregating and normalizing _columnwise_ (classwise): \n\n   $$\\begin{align*}\n   \\mathbf{p}_{\\text{Valid}} &= \\left(\\frac{\\text{\\# of Word 1}}{\\text{Total \\# of Words}}, \\frac{\\text{\\# of Word 2}}{\\text{Total \\# of Words}}, \\dots\\right) \\\\\n   &= \\left(\\frac{20}{200}, \\frac{10}{200}, \\dots\\right) \\\\\n   &= (10\\%, 5\\%, 40\\%, 10\\%, 10\\%, 20\\%, 5\\%)\n   \\end{align*}$$\n\n   Similarly: \n\n   $$\\mathbf{p}_{\\text{Spam}} = (20\\%, 25\\%, 25\\%, 25\\%, 1.25\\%, 3\\%, 0.75\\%)$$\n\n   :::\n      \n3. In order to calibrate the decision boundary for your classifiers, you\n   perform a user experience study that reveals it takes 2 minutes on average\n   to discard a spam email, while it takes 10 minutes to find an improperly\n   labeled valid email and move it to the inbox.\n\n   What *posterior* probability threshold should you select in order to\n   minimize the expected amount of wasted time?(Find $p_{\\text{thresh}}$\n   such that if the posterior probability of being spam is greater than\n   $p_{\\text{thresh}}$, the optimal choice is to treat the email as spam.)\n\n   *Hint: When the posterior probability is equal to the threshold, the\n   expected time loss of both decisions is equal.* (5 points)\n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n\n   The decision boundary should be set so that both decisions (spam / valid) have\n   the same expected time loss. If we let $p$ be the threshold probability, then \n   labeling the email as spam has an expected time loss of $10(1-p)$ and labeling \n   the email as valid has an expected time loss of $2p$. We can equate these to find\n\n   $$\\begin{align*}\n   10(1-p) &= 2p \\\\\n   10 - 10p &= 2p \\\\\n   10 &= 12p \\\\\n   p &= \\frac{5}{6}\n   \\end{align*}$$\n\n   so we set $p_{\\text{thresh}} = \\frac{5}{6}$\n:::\n\n4. Your classifier receives a new message with the text:\n    \n   ::: #email_contents\n   \n   > Hello Friend!\n   >\n   > I have a great deal for you - if you send me \\$100 today, I will double\n   > your money and send you \\$200 dollars next week. That is \\$100 absolutely free!!\n   >\n   > How am I able to offer such an amazing deal? I have a system for investing\n   > in the markets. I can study price patterns and identify stocks that are going\n   > up and ride them to the moon! No spreadsheet needed - just pure skill.\n   >\n   > I'm offering you this opportunity to double your money because I believe that\n   > this path to properity should be free to all. We don't need any fancy banks\n   > with their lies - power to the people!\n   \n   :::\n    \n   A. What is the data vector $(\\bx)$ associated with the above text? (5 points)\n  \n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n\n      We count up the words in the above text (keeping the same order as \n      earlier) to get \n\n      $$\\bx = (2, 2, 2, 2, 1, 0, 0)$$\n\n   :::\n\n   B. What is the PMF of each class associated with this data vector? (5 points)\n\n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n\n   We substitute our observed values into the multinomial PMF given above: \n\n   $$\\P(\\bx | \\text{Spam}) \\frac{9!}{2!2!2!2!1!0!0!} * 0.2^2 * 0.25^2 * 0.25^2 * 0.25^2 * 0.0125^1 * 0.03^0 * 0.0075^0 \\approx 0.00277$$\n   \n   and \n   \n    $$ \\P(\\bx | \\text{Valid}) = \\frac{9!}{2!2!2!2!1!0!0!} * 0.1^2 * 0.05^2 * 0.40^2 * 0.1^2 * 0.1^1 * 0.2^0 * 0.05^0 \\approx 9.072*10^{-5}$$\n   :::\n\n   C. What are the *posterior* probabilities of each class? (5 points)\n  \n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   We use Bayes' rule to compute the posterior probability of being spam: \n\n   $$\\begin{align*}\n   \\P(\\text{Spam} | \\bx) &= \\frac{\\P(\\bx | \\text{Spam})\\P(\\text{Spam})}{\\P(\\bx | \\text{Spam})\\P(\\text{Spam}) + \\P(\\bx | \\text{Valid})\\P(\\text{Valid})} \\\\\n   &= \\frac{0.00277 * 0.9}{0.00277 * 0.9 + 9.072*10^{-5} * 0.1} \\\\\n   &\\approx 99.6\\%\n   \\end{align*}$$\n   \n   :::\n\n   D. Should this email be marked as spam or not? (2 points)\n   \n   ::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n   \n   **Yes**. This email has a 99.6\\% chance of being spam, which is above our\n   marking threshold of $5/6$. \n   \n   :::\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}