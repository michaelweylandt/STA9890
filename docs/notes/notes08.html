<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Michael Weylandt">

<title>STA 9890 - Ensemble Learning &amp; Resampling Methods – STA 9890</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-7a426326b279d3ba9cc0818763c3c226.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">STA 9890</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href=".././syllabus.html"> 
<span class="menu-text">Syllabus</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href=".././notes.html"> 
<span class="menu-text">Handouts and Additional Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../reports.html"> 
<span class="menu-text">Research Reports</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href=".././competition.html"> 
<span class="menu-text">Course Competition</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href=".././resources.html"> 
<span class="menu-text">Additional Resources and Policies</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href=".././objectives.html"> 
<span class="menu-text">Learning Objectives</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#ensemble-learning" id="toc-ensemble-learning" class="nav-link active" data-scroll-target="#ensemble-learning">Ensemble Learning</a></li>
  <li><a href="#stacking" id="toc-stacking" class="nav-link" data-scroll-target="#stacking">Stacking</a></li>
  <li><a href="#resampling" id="toc-resampling" class="nav-link" data-scroll-target="#resampling">Resampling</a>
  <ul class="collapse">
  <li><a href="#bootstrapping" id="toc-bootstrapping" class="nav-link" data-scroll-target="#bootstrapping">Bootstrapping</a></li>
  <li><a href="#bootstrap-aggregation-bagging" id="toc-bootstrap-aggregation-bagging" class="nav-link" data-scroll-target="#bootstrap-aggregation-bagging">Bootstrap Aggregation (Bagging)</a></li>
  <li><a href="#out-of-bag-error" id="toc-out-of-bag-error" class="nav-link" data-scroll-target="#out-of-bag-error">Out of Bag Error</a></li>
  </ul></li>
  <li><a href="#boosting" id="toc-boosting" class="nav-link" data-scroll-target="#boosting">Boosting</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/michaelweylandt/STA9890/edit/main/notes/notes08.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/michaelweylandt/STA9890/blob/main/notes/notes08.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/michaelweylandt/STA9890/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">STA 9890 - Ensemble Learning &amp; Resampling Methods</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Michael Weylandt </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<p><span class="math display">\[\newcommand{\R}{\mathbb{R}}\newcommand{\bx}{\mathbf{x}}\newcommand{\bw}{\mathbf{w}} \newcommand{\P}{\mathbb{P}} \newcommand{\V}{\mathbb{V}} \newcommand{\C}{\mathbb{C}} \newcommand{\E}{\mathbb{E}}\]</span></p>
<p>To this point, we have created individual models for regression and classification tasks. We have covered regression-type models for low-dimensional settings (GLMs: mainly linear and logistic), generative models for classification (NB, LDA, QDA), purely discriminative models (SVM), and flexible non-parametric models (KNN). Building on these tools, we have developed non-linear extensions (splines and kernels) suitable for the <span class="math inline">\(n \gg p\)</span> setting and regularization techniques (ridge and lasso) necessary for the <span class="math inline">\(p \gg n\)</span> setting.</p>
<p>In each of these, we have argued that certain models (more precisely, certain estimators) have different amounts of bias and variance and given a rule of thumb that in low-data settings high-bias/low-variance models are preferred while in high-data settings, we should feel free to use low-bias models since the variance will be controlled by the large training set.</p>
<p>Furthermore, we have discussed the importance of ‘hold-outs’ (test/train splits, cross-validation, <em>etc.</em>) as a tool to avoid overfitting. If we evaluate our models on new data (or at least new to that model), we minimize the chance of ‘regurgitation’ and ensure that our models are learning true(-ish) generalizabile relationships. Importantly, we know that <em>any time</em> we make a selection, it is important to have a new data set for downstream tasks. So:</p>
<ul>
<li>If we just want to to train a single pre-specified model with no hyperparameters and use it blindly, we can use all of our data</li>
<li>If we want to to train a single pre-specified model with no hyperparameters and assess its predictive performance, we need to split our data into two sets (training + test)</li>
<li>If we want to train a model and select hyperparameters but do not need to assess its predictive performance, we need to split our data into two sets (training + ‘validation’)</li>
<li>If we want to train a model, select hyperparameters, and provide an unbiased assessment of predictive performance, we need to split our data into three sets (training + validation + test)</li>
</ul>
<p>Personally, I find the jargon of these different sets a bit confusing–what is testing and how is it different than validation?–but the ‘new data for each task’ heuristic is easy to apply and generalize.</p>
<p>Finally, we have noted that - while hold out techniques are an excellent tool for maximizing predictive performance - they aren’t the best to ensure <em>reliability of interpretation</em>. If <em>insights</em> are more important than pure <em>performance</em>, stability techniques are typically a better strategy for tuning hyperparameters.</p>
<p>For the next two weeks, we are going to go beyond this ‘single model’ paradigm and consider how we might handle scenarios where we have two or more models available for our use. This is the domain of <em>ensemble learning</em> - building models consisting of multiple ‘sub-models’, termed ‘base learners’. Ensemble learning is particularly powerful when applied in conjunction with fast and flexible base learners, so we will also use this as a jumping off point for one more class of models.</p>
<section id="ensemble-learning" class="level2">
<h2 class="anchored" data-anchor-id="ensemble-learning">Ensemble Learning</h2>
<p>We begin with a discussion of <em>ensemble learning</em>, the task of combining multiple (simpler) models into a ‘super model’ to achieve a task. Ensembles can be used for essentially any ML task, but we will focus on ensemble learning for the two tasks we have focused on to date: regression and classification. (The differences in these two tasks will not really have any bearing on our ‘ensembling’ discussion.)</p>
<p>Suppose that we want to predict the outcome of some variable <span class="math inline">\(Y\)</span> using two <em>statistically independent</em> predictors <span class="math inline">\(\hat{Y}_1, \hat{Y}_2\)</span>: if <em>arguendo</em> we assume these are unbiased, the MSE of each prediction is simply</p>
<p><span class="math display">\[\begin{align*}
\text{MSE}_{\hat{Y}_i} &amp;= \E_{Y, \hat{Y}_i}[(Y - \hat{Y}_i)^2] \\
                       &amp;= \E_{Y, \hat{Y}_i}[(Y - \E[Y] + \E[Y] - \hat{Y}_i)^2] \\
                       &amp;= \E_{Y, \hat{Y}_i}[(Y - \E[Y])^2 +2(Y - \E[Y])(\E[Y] - \hat{Y}_i)+(\E[Y] - \hat{Y}_i)^2] \\
                       &amp;= \E_{Y}[(Y - \E[Y])^2 +2\E_{Y, \hat{Y}_i}[(Y - \E[Y])(\E[Y] - \hat{Y}_i)]+\E_{\hat{Y}_i}[(\E[Y] - \hat{Y}_i)^2] \\
                       &amp;= \sigma_Y^2 + 2\E_{Y}[Y - \E[Y]]\E_{\hat{Y}_i}[\E[Y] - \hat{Y}_i)] + \sigma^2_{\hat{Y}_i} \\
                       &amp;= \sigma_Y^2 + \sigma^2_{\hat{Y}_i}
\end{align*}\]</span></p>
<p>(Why do the cross terms vanish?) That is, the MSE is simply sum of the ‘irreducible error’ associated with the best possible prediction (<span class="math inline">\(\sigma_Y^2\)</span> against the optimal prediction <span class="math inline">\(\E[Y]\)</span>) and the variance (error) in <span class="math inline">\(\hat{Y}_i\)</span> as an estimator of <span class="math inline">\(\E[Y]\)</span>.</p>
<p>If <span class="math inline">\(\hat{Y}_1, \hat{Y}_2\)</span> are both predictors of <span class="math inline">\(Y\)</span>, it is natural to ask if we can do better using a <em>combination</em> of the two of them than we can with either separately. Indeed, if we let <span class="math inline">\(\widehat{Y} = \frac{1}{2}(\hat{Y}_1 + \hat{Y}_2)\)</span>, the above analysis tells us:</p>
<p><span class="math display">\[\begin{align*}
\text{MSE}_{\widehat{Y}} &amp;= \sigma_Y^2 + \sigma_{\widehat{Y}}^2 \\
&amp;= \sigma_Y^2 + \mathbb{V}\left[\frac{\hat{Y}_1 + \hat{Y}_2}{2}\right] \\
&amp;= \sigma_Y^2 + \sigma_{\hat{Y}_1}^2/4 + \sigma_{\hat{Y}_2}^2/4
\end{align*}\]</span></p>
<p>How does this compare to the separate predictions? Well, if <span class="math inline">\(\sigma_{\hat{Y}_1} = \sigma_{\hat{Y}_2}\)</span>, then we have clearly reduced our expected MSE by half of the variance error. (By definition, we can’t do anything about the irreducible error.) If, on the other hand, one predictor is much better than the other, say <span class="math inline">\(\sigma_{\hat{Y}_1}^2 = 400 \sigma_{\hat{Y}_2}^2\)</span>, then we have</p>
<p><span class="math display">\[\begin{align*}
\text{MSE}_{\hat{Y}_1} &amp;= \sigma_Y^2 + 400 \sigma_{\hat{Y}_2}^2 \\
\text{MSE}_{\hat{Y}_2} &amp;= \sigma_Y^2 + \sigma_{\hat{Y}_2}^2 \\
\text{MSE}_{\widehat{Y}} &amp;= \sigma_Y^2 + 100.25 \sigma_{\hat{Y}_2}^2 \\
\end{align*}\]</span></p>
<p>So we don’t beat the superior predictor (<span class="math inline">\(Y_2\)</span>), but we comfortably beat the inferior predictor (<span class="math inline">\(Y_1\)</span>). Notably, if we didn’t know which predictor was better and had to select randomly (50/50), we would have an expected MSE of <span class="math inline">\(\sigma_Y^2 + 200\sigma_{\hat{Y}_2}^2\)</span>, so the ‘averaging’ predictor is still better. More generally, if <span class="math inline">\(\hat{Y_1}\)</span> is sometimes better and <span class="math inline">\(\hat{Y_2}\)</span> is better at other times, a suitable averaging strategy will do better <em>in the long run</em> than using a single predictor. (We should pick the averaging weights as a function of the variance of the two approaches and the relatively frequencies of the <span class="math inline">\(\hat{Y}_1\)</span>-better and <span class="math inline">\(\hat{Y}_2\)</span>-better scenarios.)</p>
<p>This example - simple as it is - gets at the core insight of stacking: if we have several ‘good enough’ models, we can do better - sometimes much better - by using a combination of them. This is not guaranteed - if <span class="math inline">\(\hat{Y}_2\)</span> is always the ‘lower variance’ model, adding in some <span class="math inline">\(\hat{Y}_1\)</span> pretty much always hurts - but we do not expect to have a single ‘dominant’ model. In practice, we typically find ourselves armed with models of similar-enough performance (logistic regression, linear SVMs, RBF Kernel SVMs, RBF Kernel logistic regression) and find that different models perform better on different inputs. <em>E.g.</em>, the ‘linear’ models might do well far from the decision boundary, while the ‘kernelized’ models might improve performance near the decision boundary while suffering from extra ‘wiggliness’ (variance) far from the decision boundary.</p>
<p>So what can we take away from this discussion?</p>
<blockquote class="blockquote">
<p>Low correlation among predictors is helpful. If our base learners give the same predictions at every point, there’s nothing to be gained by combining and comparing them.</p>
</blockquote>
<p>Put another way, ensemble learning benefits from a <em>diverse</em> set of base learners. We hope to ‘combine strength’ from different approaches to build an ensemble predictor that is better than any of its individual components.</p>
<p>The three major ensembling techniques we will cover - stacking, bagging, and boosting - essentially come down to different ways of getting this diversity.</p>
</section>
<section id="stacking" class="level2">
<h2 class="anchored" data-anchor-id="stacking">Stacking</h2>
<p>So this is all well and good, but where do we <em>actually get</em> different predictors? Here, we’re going to change notation to <span class="math inline">\(\hat{f}_1, \hat{f}_2, \dots
\hat{f}_K\)</span> to emphasize that we want to learn a combination of <em>predictors</em> (functions estimated from data), not <em>predictions</em>.</p>
<p>Well… perhaps the easiest thing to do is to train different models on the same data. Logistic Regression, LDA, and SVMs will likely find <em>similar</em> decision boundaries, but they won’t be exactly the same. Suppose we have</p>
<ul>
<li><span class="math inline">\(\hat{f}_{\text{LR}}\)</span>: Logistic Regression (for simplicity, plain and unregularized)</li>
<li><span class="math inline">\(\hat{f}_{\text{LDA}}\)</span>: Linear Discriminant Analysis</li>
<li><span class="math inline">\(\hat{f}_{\text{SVM}}\)</span>: A Linear SVM with the default hyperparameter from <code>sklearn</code></li>
</ul>
<p>Further, let’s assume that we have the binarized predictions (<span class="math inline">\(\{0, 1\}\)</span>, no soft labels for now) from each model. How can we combine these?</p>
<p>Perhaps the simplest rule is the ‘majority vote’ rule: if <span class="math inline">\(\hat{f}_{\text{LR}}(\bx) = \hat{f}_{\text{LDA}}(\bx) = 1\)</span> and <span class="math inline">\(\hat{f}_{\text{SVM}}(\bx) = 0\)</span>, then <span class="math inline">\(\hat{f}_{\text{Majority}}(\bx) = 1\)</span>.</p>
<p>This approach is quite easy to implement, but it treats all the inputs as equally reliable. While this isn’t the <em>worst</em> assumption, we can do better. In particular, what if we <em>learned</em> an optimal set of weights. Specifically, we want to learn a vector of weights <span class="math inline">\(\bw \in \mathbb{R}^3\)</span> to maximize predictive accuracy of the linear combination <span class="math inline">\(w_1 \hat{f}_{\text{LR}} + w_2 \hat{f}_{\text{LDA}} + w_3 \hat{f}_{\text{SVM}}\)</span>. This gives us another classification problem, so let’s use logistic regression to determine the weights:</p>
<p><span class="math display">\[\hat{\bw} = \text{arg min}_{\bw} \sum_{i=1}^n -y_i \bw^{\top}\hat{\mathbf{f}} + \log(1 + e^{\bw^{\top}\hat{\mathbf{f}}})\]</span> where <span class="math inline">\(\hat{\mathbf{f}}\)</span> is a vector of the three base learner predictions.</p>
<p>The solution to this problem, <span class="math inline">\(\hat{\bw}\)</span>, gives the <em>stacking weights</em> for our three base learners. Once we have <span class="math inline">\(\hat{\bw}\)</span>, we can make predictions at our our new test point, <span class="math inline">\(\tilde{\bx}\)</span>, by:</p>
<ol type="1">
<li>Apply three base learners separately:
<ul>
<li><span class="math inline">\(\hat{y}_{\text{LR}} = \hat{f}_{\text{LR}}(\tilde{\bx})\)</span></li>
<li><span class="math inline">\(\hat{y}_{\text{LDA}} = \hat{f}_{\text{LDA}}(\tilde{\bx})\)</span><br>
</li>
<li><span class="math inline">\(\hat{y}_{\text{SVM}} = \hat{f}_{\text{SVM}}(\tilde{\bx})\)</span></li>
</ul></li>
<li>Determine the weighted combination:
<ul>
<li><span class="math inline">\(\text{Stacking Score} = w_1\hat{y}_{\text{LR}} + w_2\hat{y}_{\text{LDA}}+w_3\hat{y}_{\text{SVM}}\)</span></li>
</ul></li>
<li>Make a prediction using the stacking score: <span class="math display">\[\hat{y}_{\text{Ensemble}} = \begin{cases} 1 &amp; \text{ if } \text{Stacking Score} &gt; \theta \\ 0 &amp; \text{ if } \text{ Stacking Scoore} \leq \theta \end{cases}\]</span> where <span class="math inline">\(\theta\)</span> is a threshold chosen to minimize the problem-specific loss. (Alternatively, set <span class="math inline">\(\theta = 0\)</span> and include an intercept term.)</li>
</ol>
<p>We note a few practical points here:</p>
<ol type="1">
<li>What data should we use to estimate <span class="math inline">\(\bw\)</span>? This is a new step in our pipeline, so we need a new ‘chunk’ of our data. This split of the data is typically called either a query or validation set, but I tend to describe it as an ‘ensembling’ set to make its purpose clear. Regardless, it serves to give us a new data set to fit our new ensemble model. (If we use the training set used to train each <span class="math inline">\(\hat{f}_i\)</span>, the base learners will look ‘too good’ to the ensemble learning process.)</li>
<li>Nothing actually requires us to use the binarized predictions. For models that provide soft labels (class probabilities), we can and should use those in the ensemble process (both in training the ensemble weights and in constructing the predictor vectors <span class="math inline">\(\hat{\mathbf{f}}\)</span>). Dropping the probabilities is really just throwing away data.</li>
<li>We motivated stacking by weighted averages. As such it is common to add additional constraints to the stacking problem to make it look more like averaging. For example, you will often see:
<ul>
<li><span class="math inline">\(\bw \geq 0\)</span>: The stacking weights are non-negative. This makes sense if you assume each predictor is generally reasonable.</li>
<li><span class="math inline">\(\sum w_i = 1\)</span>: The stacking weights sum to 1. Again, a natural generalization of averaging.</li>
</ul></li>
<li>When fitting <em>large</em> ensembles (like any large model), it is not uncommon to see ridge or lasso penalties. These are particularly important in ensemble building since the base learners are generally highly correlated.</li>
<li>Suitably tuned (and that’s a big assumption!) stacking should never do worse than any individual predictor because we can always pick <span class="math inline">\(\bw = (1, 0, 0)\)</span> if the first base learner dominates the others.</li>
</ol>
<p>Stacking creates a ‘model of models’ - the turducken of machine learning - and all of the ML tricks we have learned to date can be used in creating this meta-model. Like any modeling step, we have to practice good data hygiene (splitting and hold outs) to make sure we don’t overfit and to generate a good estimate of predictive accuracy, but otherwise it is particularly straightforward.</p>
<p>Stacking can only take us so far: the value-added of stacking comes from differences between the base learners and, when trained on the same data set, we don’t expect too much diversity among the base learners. In practical settings, stacking is particularly useful when we are given ‘standard’ or ‘baseline’ models for a task that we want to combine without changing the individual models, but we may want to modify our pipeline to explicitly generate more diversity.</p>
<p>This brings us to our next family of ensembling techniques - resampling methods, the most famous of which is <em>bootstrap aggregation</em> or bagging.</p>
</section>
<section id="resampling" class="level2">
<h2 class="anchored" data-anchor-id="resampling">Resampling</h2>
<p>In our discussion above, we argued that diversity of (variance between) base learners was key to ensemble performance. When these base learners are trained on the same training data, we can only get so much variance. Since most of our models are not terrible, they generally pick out the same major patterns in the data.</p>
<p>So how can we get more variance? We could further split our training data, using a small chunk for each model, but this seems likely to bring about variance problems. If we want to fit large ensembles of 10, 20, or even 100 models, we might wind up using less than 1% of the overal data to train a single model, which is clearly subpar.</p>
<p>We can get around this problem using <em>sampling</em> or <em>resampling</em> techniques. We can train our esnemble members on randomly selected subsets of our data (or subsets of the features). Because these models have different training sets, they will be more varied. (Typically, this sort of ‘data randomization’ induces more variance than just changing hyperparamters or model families.)</p>
<p>These randomization schemes have different names:</p>
<ul>
<li>Minibatching: training on random subsets of samples (rows)</li>
<li>Random Subspace Method: training on random subsets of features (columns)</li>
<li>Minipatching: training on random subsets of samples and features (row and columns)</li>
</ul>
<p>If the model is not too sensitive to the sample size (or if we use a high sampling rate), these strategies can work well.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> But we have a bit of a bind here: if we want to use large training sets for each learner, we go back to the overlapping training scenario we were trying to avoid.</p>
<p>Can we be a bit more creative on our sampling? We want to minimize overlap but also get ‘full sized’ training sets.</p>
<section id="bootstrapping" class="level3">
<h3 class="anchored" data-anchor-id="bootstrapping">Bootstrapping</h3>
<p>To get around this problem, we rely on a key idea of late 20th century statistics: <strong>the bootstrap.</strong><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> Recall the core idea of bootstrapping:</p>
<ul>
<li>We have samples <span class="math inline">\(\{(\bx_1, y_1), (\bx_2, y_2), \dots, (\bx_n, y_n)\}\)</span> from an unknown distribution.</li>
<li>We would like to have more samples from this distribution, but we don’t have the ability to gain more data.</li>
<li>If our data set is large, we expect that the <em>empirical distribution</em> <span class="math inline">\(\hat{\P}_n\)</span> will be close to the ‘real’ distribution <span class="math inline">\(\P\)</span>. Formally, the law of large numbers (and its fancy variants like Glivenko-Cantelli) guarantees us that <span class="math inline">\(\hat{P}_n \to \P \text{ as } n \to \infty\)</span>.</li>
<li>Sampling from <span class="math inline">\(\hat{P}_n\)</span> is ‘close’ to sampling from <span class="math inline">\(\P\)</span></li>
</ul>
<p>So how can we sample from the empirical distribution <span class="math inline">\(\hat{P}_n\)</span>? We sample <em>with replacement</em>. That is, we pick one of the training points <span class="math inline">\(n\)</span> times <strong>independently</strong> (with no regard for prior selections). Intuitively, this captures the idea of IID sampling - it’s also necessary so we don’t just reproduce the (shuffled) training data.</p>
<p>This scheme - sampling with replacement - is the essence of <strong>bootstrap sampling</strong>.</p>
</section>
<section id="bootstrap-aggregation-bagging" class="level3">
<h3 class="anchored" data-anchor-id="bootstrap-aggregation-bagging">Bootstrap Aggregation (Bagging)</h3>
<p>We can use a similar strategy to generate ‘new’ training data for our base learners:</p>
<ul>
<li>Repeat <span class="math inline">\(b=1, \dots, B\)</span> times:
<ul>
<li>Sample from the training data <span class="math inline">\(\mathcal{D}_{\text{train}}\)</span> <span class="math inline">\(n\)</span> times <em>with replacement</em> to get a bootstrap set <span class="math inline">\(\tilde{\mathcal{D}_b}\)</span></li>
<li>Train a base learner <span class="math inline">\(\hat{f}_b\)</span> on <span class="math inline">\(\tilde{\mathcal{D}_b}\)</span></li>
</ul></li>
<li>Create the ensemble predictor: <span class="math display">\[\hat{f}(\bx) = \frac{1}{B}\sum_{b=1}^B \hat{f}_b(\bx)\]</span></li>
</ul>
<p>This ensembling strategy is called <strong>bootstrap aggregation</strong> or more simply <strong>bagging</strong>.</p>
<p>So how much diversity / variance can we actually expect from this strategy? It depends on how much overlap we get in our sampling. This is a fun little probability exercise:</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Probability of a Given Sample Being in a Bootstrap Data Set">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Probability of a Given Sample Being in a Bootstrap Data Set
</div>
</div>
<div class="callout-body-container callout-body">
<p>In our scenario above, what is the chance that <span class="math inline">\(\bx_1\)</span> is in <span class="math inline">\(\tilde{\mathcal{D}}_b\)</span>?</p>
<p>For each sample, there is a <span class="math inline">\(1/n\)</span> chance that we select <span class="math inline">\(\bx_1\)</span>, and hence a <span class="math inline">\(1-1/n\)</span> chance that we don’t. If we repeat this process <span class="math inline">\(n\)</span> times, there is a <span class="math inline">\((1-1/n)^n\)</span> chance that we never select <span class="math inline">\(\bx_1\)</span>. For a large data set, this converges to</p>
<p><span class="math display">\[\lim_{n\to\infty}\left(1-\frac{1}{n}\right)^n = e^{-1} \approx \frac{2}{3}\]</span></p>
<p>so about <span class="math inline">\(2/3\)</span> of our data is used for each base learner. <em>Unlike</em> straight subsampling, however, this process includes repeats, so we have <span class="math inline">\(n\)</span> samples, guaranteeing us repeats. (A more detailed analysis can show that the <em>number</em> of times a sample appears is asymptotically Poisson.)</p>
</div>
</div>
<p>So how does bagging actually work? We know that we’re always trying to control bias and variance so let’s look at those two terms separately:</p>
<ul>
<li>Bias: Because we are fitting the same model <span class="math inline">\(B\)</span> times, there’s really no impact on bias. (<em>E.g.</em>, if we are fitting a linear model, the average of <span class="math inline">\(B\)</span> lines is just another line so whatever approximation error we have is unchanged.)</li>
<li>Variance: Suppose that the base learners <span class="math inline">\(\hat{f}_i\)</span> have variance <span class="math inline">\(\sigma^2\)</span> and correlation <span class="math inline">\(\rho\)</span>. (These are constant for all <span class="math inline">\(\hat{f}_i, \hat{f}_j\)</span> by the IID sampling structure used). Then the variance of <span class="math inline">\(\hat{f}\)</span> (the bagged average) is given by</li>
</ul>
<p><span class="math display">\[\begin{align*}
\V[\hat{f}] &amp;= \V\left[\frac{1}{B}\sum_b \hat{f}_b\right] \\
            &amp;= B^{-2}\V\left[\sum_b \hat{f}_b\right] \\
            &amp;= B^{-2}\left(\sum_{b=1}^B \V[\hat{f}_b] + \sum_{\substack{b, b'=1 \\ b \neq b'}}^B \C[\hat{f}_b, \hat{f}_{b'}]\right)\\
            &amp;= B^{-2}\left(\sum_{b=1}^B \sigma^2 + \sum_{\substack{b, b'=1 \\ b \neq b'}}^B \rho\sigma^2\right) \\
            &amp;= B^{-2}\left(B\sigma^2 + (B^2 - B) \rho\sigma^2\right) \\
            &amp;= B^{-2}\left(B(\rho\sigma^2 + (1-\rho)\sigma^2) + (B^2 - B) \rho\sigma^2\right) \\
            &amp;= B^{-2}\left(B\rho\sigma^2 + B(1-\rho)\sigma^2) + B^2\rho\sigma^2 - B\rho\sigma^2\right) \\
            &amp;= B^{-2}\left(B(1-\rho)\sigma^2) + B^2\rho\sigma^2\right) \\
            &amp;= \rho\sigma^2 + \frac{1}{B}(1-\rho)\sigma^2
\end{align*}\]</span></p>
<p>This is an interesting formula. As always, we can understand it best by taking the extremes:</p>
<ul>
<li><span class="math inline">\(B = 1\)</span>: In this case, the variance reduces to <span class="math inline">\(\sigma^2\)</span>, the variance of a single predictor (as we would expect for ‘ensemble of one’).</li>
<li><span class="math inline">\(B \to \infty\)</span>: The variance decreases to <span class="math inline">\(\rho\sigma^2\)</span>, but no further. Practically, we see diminishing returns in the <span class="math inline">\(B\approx 200-500\)</span> range, which you will see as the default for most software that has a bagging step.</li>
<li><span class="math inline">\(\rho \to 1\)</span>: As the base learners become more correlated, the variance converges to <span class="math inline">\(\sigma^2\)</span>, the variance of a single predictor. (As we would expect since we have no diversity among base learners.)</li>
<li><span class="math inline">\(\rho \to 0\)</span>: As the base learners become uncorrelated, the variance converges to <span class="math inline">\(\sigma^2/B\)</span>, the variance of a standard average. (You might ask why not take <span class="math inline">\(B \to \infty\)</span> in this case to have no bias: we really can’t get an infinite number of uncorrelated models, no matter how hard we try, if they are modeling the same underlying DGP)</li>
</ul>
<p>So we see we want a flexible (low-bias) base learner that is also going to give us low correlation (and low variance) among the bagged predictors. How can we get such a base learner? We’ll cover this more next week.</p>
</section>
<section id="out-of-bag-error" class="level3">
<h3 class="anchored" data-anchor-id="out-of-bag-error">Out of Bag Error</h3>
</section>
</section>
<section id="boosting" class="level2">
<h2 class="anchored" data-anchor-id="boosting">Boosting</h2>
<p>Delayed to next week…</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Most of these methods were actually designed to speed up training/fitting and that remains the main use case for minibatching today (in <em>stochastic gradient descent</em>). We won’t focus too much on implications for speed today.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>If you have seen bootstrapping before, it was likely in the context of estimating the sampling variance of an estimator. (If you haven’t seen this, go look it up - it’s awesome!) Here, we’re using bootstrap sampling to induce some variance, not to estimate variance, but the sampling strategy is the same.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/michael-weylandt\.com\/STA9890\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/michaelweylandt/STA9890/edit/main/notes/notes08.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/michaelweylandt/STA9890/blob/main/notes/notes08.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/michaelweylandt/STA9890/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>