<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>STA 9890 - Introduction to Classification – STA 9890</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-7a426326b279d3ba9cc0818763c3c226.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">STA 9890</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href=".././syllabus.html"> 
<span class="menu-text">Syllabus</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href=".././notes.html"> 
<span class="menu-text">Handouts and Additional Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../reports.html"> 
<span class="menu-text">Research Reports</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href=".././competition.html"> 
<span class="menu-text">Course Competition</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href=".././resources.html"> 
<span class="menu-text">Additional Resources and Policies</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href=".././objectives.html"> 
<span class="menu-text">Learning Objectives</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#a-taxonomy-of-classification" id="toc-a-taxonomy-of-classification" class="nav-link active" data-scroll-target="#a-taxonomy-of-classification">A Taxonomy of Classification</a></li>
  <li><a href="#metrics-of-classification-accuracy" id="toc-metrics-of-classification-accuracy" class="nav-link" data-scroll-target="#metrics-of-classification-accuracy">Metrics of Classification Accuracy</a>
  <ul class="collapse">
  <li><a href="#combining-metrics" id="toc-combining-metrics" class="nav-link" data-scroll-target="#combining-metrics">Combining Metrics</a></li>
  <li><a href="#trade-off-of-recall-and-precision" id="toc-trade-off-of-recall-and-precision" class="nav-link" data-scroll-target="#trade-off-of-recall-and-precision">Trade-Off of Recall and Precision</a></li>
  <li><a href="#scoring-functions" id="toc-scoring-functions" class="nav-link" data-scroll-target="#scoring-functions">Scoring Functions</a></li>
  </ul></li>
  <li><a href="#types-of-classification-methods" id="toc-types-of-classification-methods" class="nav-link" data-scroll-target="#types-of-classification-methods">Types of Classification Methods</a></li>
  <li><a href="#building-mutliclass-classifiers-from-binary-classifiers" id="toc-building-mutliclass-classifiers-from-binary-classifiers" class="nav-link" data-scroll-target="#building-mutliclass-classifiers-from-binary-classifiers">Building Mutliclass Classifiers from Binary Classifiers</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/michaelweylandt/STA9890/edit/main/notes/notes05.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/michaelweylandt/STA9890/blob/main/notes/notes05.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/michaelweylandt/STA9890/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">STA 9890 - Introduction to Classification</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><span class="math display">\[\newcommand{\by}{\mathbf{y}} \newcommand{\Ycal}{\mathcal{Y}}\]</span></p>
<p>As we move into Unit II of this course, we turn our focus to <em>classification</em>.</p>
<section id="a-taxonomy-of-classification" class="level2">
<h2 class="anchored" data-anchor-id="a-taxonomy-of-classification">A Taxonomy of Classification</h2>
<p>Recall from before that we defined <em>regression</em> as the subset of supervised learning where the response (<span class="math inline">\(\by\)</span>) was a continuous variable, or at least one that is appropriate to model as such.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> By contrast, <em>classification</em> considers <span class="math inline">\(\by\)</span> to take values in a discrete set. Though this restriction may feel limiting, it is actually quite powerful. We consider several different forms of classification, based on the <em>support</em> of <span class="math inline">\(\by\)</span>:</p>
<ul>
<li><p><em>Binary</em> classification: in this simplest case, <span class="math inline">\(\by\)</span> takes one of two values, which we conventionally code as <span class="math inline">\(\{0, 1\}\)</span> or <span class="math inline">\(\{-1, +1\}\)</span>, depending on which makes the math easier. Note that the actual response need not be these numbers; they are simply a mathematical convenience.</p>
<p>Examples of binary classification include:</p>
<ul>
<li>Does an incoming student graduate within the next 6 years or no?</li>
<li>Does a patient have a given disease?</li>
<li>Is there a dog present in an image?</li>
<li>Is this applicant qualified for a job?</li>
</ul>
<p>Note that, in at least two of these, the underlying question is (arguably) not quite so binary, but we may choose to treat it as such. In particular, when assessing onset of a disease, the actual impairment to the patient is continuous, but it is common in medical practice to “binarize” the outcome. Any of you with aging family members know that cognitive decline occurs long before it’s ‘officially’ Alzheimer’s. Similarly, qualification for a job is perhaps best understood as a continuous (or even purely comparative) quantity “Is A more qualified than B?” but we chooes to binarize it when deciding to whom a job offer should be made.</p>
<p>Recalling your probability theory, there is (essentially) only one distribution on <span class="math inline">\(\{0, 1\}\)</span>, the Bernoulli, so this scenario typically has the cleanest and simplest mathematics.</p></li>
<li><p><em>Multiclass</em> classification: in this case, <span class="math inline">\(\by\)</span> takes values in a set of finite and known, but potentially large, set of outcomes, which we will call <span class="math inline">\(\Ycal\)</span>. Before about 20 years ago, multiclass problems took <span class="math inline">\(|\Ycal|\)</span> to be not much larger than 2, <em>e.g.</em>, which blood type does a sample match or what language is a text sample written in, but much of the modern practical success of machine learning comes from the ability to treat <em>very large</em> outcome sets <span class="math inline">\(\Ycal\)</span>.</p>
<p>For instance, modern computer vision (CV) has moved beyond far simple binary classification:</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/ACmydtFDTGs" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>The famed<a href="https://en.wikipedia.org/wiki/ImageNet"><code>ImageNet</code></a> benchmark data set has over 20,000 classes (arranged with additional structure) and modern data sets include even more. This can be contrasted with the older <a href="https://en.wikipedia.org/wiki/MNIST_database"><code>MNIST</code></a> data set which collects only ten handwritten digits.</p>
<p>Beyond CV, large multiclass classification has also revolutionized text modeling: when a chatbot generates text, it selects the next word from a large but finite set of English words.</p>
<p>Just like binary classification is rooted in the Bernoulli distribution, multiclass classification is rooted in the <a href="https://en.wikipedia.org/wiki/Categorical_distribution">categorical distribution</a>. When applied to a large class of outcomes, the categorical distribution becomes a <a href="https://en.wikipedia.org/wiki/Multinomial_distribution">multinomial</a>, <em>cf</em> Bernoulli to binomial, so multiclass classification is also frequently called <em>multinomial</em> classification.</p></li>
</ul>
<p>While our main focus is on <em>binary</em> and <em>multiclass</em> problems, it is worth noting some additional “modes” of classification.</p>
<ul>
<li><p><em>Ordinal</em> classification: in this case, <span class="math inline">\(\Ycal\)</span> is an <em>ordered</em> set. The most common form of ordinal classification is the ubiquitous <a href="https://en.wikipedia.org/wiki/Likert_scale"><em>Likert scale</em></a> which you have certainly encountered any time you have filled out a customer survey:</p>
<ul>
<li><em>Strongly Agree</em></li>
<li><em>Agree</em></li>
<li><em>Neutral</em></li>
<li><em>Disagree</em></li>
<li><em>Strongly Disagree</em></li>
</ul>
<p>In this case, the categories clearly have an order and a ranking, but we can’t quite treat them as ‘numerical’ in the usual sense: <em>Strongly Agree</em> is not just <em>Agree</em> + <em>Disagree</em>.</p>
<p>Proper analysis of <em>ordinal</em> data is tricky and often poorly done. Complexities include the inappropriateness of statisticians’ most beloved tool, averaging<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, and a fundamental ‘subjectiveness.’ Another common ordinal classification problem is the assignment of grades (A &gt; B &gt; C …). In this case, students and professors may agree that one piece of work may be better than another, but a student may feel their assignment deserves an A while the professor may judge it B work. It is quite difficult to infer each individual’s personal threshold for each category without extensive analysis.</p>
<p>We will not discuss ordinal data much in this course as it requires specialized methods. Typically ordinal data is modeled by treating the response as a rounded version of some underlying continuous variable: <em>e.g.</em>, when grading hurricanes the classes (Category 1, Category 2, …) are derived from the underlying continuous variable of wind speed. This ‘hidden regression’ structure makes analysis of ordinal classification much closer to regression than binary classification.</p></li>
</ul>
<ul>
<li><p><em>Probabilistic</em> classification: we noted above that binary classification can be thought of as modeling a Bernoulli random variable. If we shift our focus to modeling the Bernoulli parameter (the probability <span class="math inline">\(p \in [0, 1]\)</span>) than the outcome (<span class="math inline">\(y \in \{0, 1\}\)</span>), we have the paradigm of <em>probabilistic</em> classification.</p>
<p>As a general rule, <em>statistically</em>-grounded classification methods have a natural probabilistic output built-in while methods coming from the CS tradition are not inherently probabilistic. Because probabilistic estimates are often quite useful, there exist several <a href="https://en.wikipedia.org/wiki/Platt_scaling">useful methods</a> to ‘bolt-on’ probabilistic outputs to pure binary classifiers.</p></li>
</ul>
</section>
<section id="metrics-of-classification-accuracy" class="level2">
<h2 class="anchored" data-anchor-id="metrics-of-classification-accuracy">Metrics of Classification Accuracy</h2>
<p>In the regression context, we had a relatively small number of loss functions:</p>
<ul>
<li>Mean Squared Error (MSE): mathematically convenient, easy interpretation, natural for OLS, optimizes for mean</li>
<li>Mean Absolute Error (MAE): mathematically a bit tricky, most practical in many circumstances, gives rise to <em>robust</em> regression, optimizes for median</li>
<li>Mean Absolute Percent Error (MAPE)</li>
<li>Checkmark/Pinball Loss: gives rise to <em>quantile</em> estimation</li>
<li>Huber loss: interpolates MSE and MAE</li>
</ul>
<p>By contrast, in the classification context, we have <em>many</em> loss functions to work with. To get into them, it’s worth thinking back to the formalism of <em>statistical hypothesis testing</em>. Recall that, in hypothesis testing, we have a 2-by-2 table of possible outcomes:</p>
<table class="caption-top table">
<caption>Hypothesis Testing Table</caption>
<colgroup>
<col style="width: 20%">
<col style="width: 23%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th colspan="2" style="text-align: center;"><strong>Truth</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Decision</strong></td>
<td style="text-align: center;"><strong>Null</strong></td>
<td style="text-align: center;"><strong>Alternative</strong></td>
</tr>
<tr class="even">
<td><strong>Retain</strong> <strong>Null</strong></td>
<td style="text-align: center;">True Negative</td>
<td style="text-align: center;">False Negative (Type II Error)</td>
</tr>
<tr class="odd">
<td><strong>Reject</strong> <strong>Null</strong></td>
<td style="text-align: center;">False Positive (Type I Error)</td>
<td style="text-align: center;">True Positive</td>
</tr>
</tbody>
</table>
<p>Suppose that we have a large number (<span class="math inline">\(n\)</span>) of binary classification points. If we let <span class="math inline">\(\hat{y}_i\)</span> be our prediction and <span class="math inline">\(y^*_i\)</span> be the actual outcome, we can construct a similar table:</p>
<table class="caption-top table">
<caption>Classification Outcome Table</caption>
<colgroup>
<col style="width: 23%">
<col style="width: 25%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th colspan="2" style="text-align: center;"><strong>Truth</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Prediction</strong></td>
<td style="text-align: center;"><span class="math inline">\(y_i^* = 0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(y_i^* = 1\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\hat{y}_i=0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(n_{00}\)</span> True Negatives</td>
<td style="text-align: center;"><span class="math inline">\(n_{01}\)</span> False Negative (Type II Errors)</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\hat{y}_i=1\)</span> <strong>Null</strong></td>
<td style="text-align: center;"><span class="math inline">\(n_{10}\)</span> False Positives (Type I Errors)</td>
<td style="text-align: center;"><span class="math inline">\(n_{11}\)</span> True Positives</td>
</tr>
</tbody>
</table>
<p>From this structure, we get several useful ideas:</p>
<ul>
<li><p>A <em>confusion matrix</em> is a 2x2 (or <span class="math inline">\(K\)</span>-by-<span class="math inline">\(K\)</span> for <span class="math inline">\(K\)</span>-multiclass problems) table comparing the right answer (here “Truth” on the columns) with our guess (here “Decision” on the rows). A good classifier will have large values “on diagonal” (<span class="math inline">\(n_{00} + n_{11}\)</span>) and small values “off diagonal” (<span class="math inline">\(n_{01} + n_{10}\)</span>)</p></li>
<li><p>The notion of <em>true/false</em> <em>positive/negatives</em>. These can be a bit tricky to remember, but the convention is:</p>
<ul>
<li>The <em>noun</em> (positive/negative) captures the <em>prediction</em></li>
<li>The <em>adjective</em> (true/false) assesses the prediction</li>
</ul>
<p>So a “false positive” means that we guessed the positive (+1) class, but that we were wrong and the truth was the negative (-1 or 0) class.</p></li>
</ul>
<p>From this simple count table, we can create <em>many</em> different ratios. I find the statistical terminology a bit more intuitive than the ML terminology:</p>
<ul>
<li>True Positive Rate: Of the predicted positives (<span class="math inline">\(\hat{y}=1\)</span>), what fraction are <em>true</em> positives (<span class="math inline">\(y^* = 1\)</span>)? <span class="math inline">\(\text{TPR} = n_{11}/(n_{01} + n_{11})\)</span></li>
<li>False Positive Rate: Of the predicted positives (<span class="math inline">\(\hat{y}=1\)</span>), what fraction are <em>false</em> positives (<span class="math inline">\(y^* = 0\)</span>)? <span class="math inline">\(\text{FPR} = n_{10}/(n_{10} + n_{11})\)</span></li>
<li>True Negative Rate: Of the predicted positives (<span class="math inline">\(\hat{y}=0\)</span>), what fraction are <em>true</em> negatives (<span class="math inline">\(y^* = 0\)</span>)? <span class="math inline">\(\text{FNR} = n_{00}/(n_{00} + n_{01})\)</span></li>
<li>False Negative Rate: Of the predicted positives (<span class="math inline">\(\hat{y}=0\)</span>), what fraction are <em>false</em> negatives (<span class="math inline">\(y^* = 1\)</span>)? <span class="math inline">\(\text{FNR} = n_{01}/(n_{00} + n_{01})\)</span></li>
</ul>
<p>These clearly satisfy some useful relationships:</p>
<p><span class="math display">\[\text{TPR} = 1 - \text{FNR} \Leftrightarrow \text{FNR} = 1 - \text{TPR}\]</span></p>
<p>and</p>
<p><span class="math display">\[\text{FPR} = 1 - \text{TNR} \Leftrightarrow \text{TNR} = 1 - \text{FPR}\]</span></p>
<p>In this scenario, we recognize the <em>false positive rate</em> as the <em>size</em> (or <em>level</em>) associated with a statistical test (5% for a 95% confidence test) and the true positive rate as the <em>power</em>.</p>
<p>The “other direction” of rates – where we condition on the truth instead of the prediction – are less common, except for the <em>false discovery rate</em>:</p>
<p><span class="math display">\[\text{FDR} = \frac{n_{10}}{n_{10} + n_{11}}\]</span></p>
<p>The FDR is commonly used in scientific settings and it answers this question: if a scientist makes <span class="math inline">\(K\)</span> discoveries, what fraction <em>of those claimed discoveries</em> are correct?</p>
<p>In ML context, you will commonly hear reference to <em>precision</em> and <em>recall</em>. With our definitions above, we have</p>
<ul>
<li>Precision = <span class="math inline">\(1 - \text{FDR}\)</span></li>
<li>Recall = <span class="math inline">\(\text{FNR} = 1 - \text{TPR}\)</span></li>
</ul>
<p>so, by maximizing precision, we ensure that all of our predicted positives are true positives and, by maximizing recall, we ensure that we have no false negatives (that is, we truly identify all of the real positives).</p>
<p>In the medical context, you may encounter alternative metrics of</p>
<ul>
<li>Sensitivity, equal to TPR</li>
<li>Specificity, equal to TNR</li>
</ul>
<p>This zoo of terms is admittedly quite confusing, but the Wikipedia article on <a href="https://en.wikipedia.org/wiki/Precision_and_recall#Definition">Precision and Recall</a> has an excellent table.</p>
<section id="combining-metrics" class="level3">
<h3 class="anchored" data-anchor-id="combining-metrics">Combining Metrics</h3>
<p>If you look at the 2x2 table above, you can convince yourself that it has two “degrees of freedom:” having a high TPR implies nothing about the TNR (or equivalent metrics). That is, it is possible to have a classifier with arbitrarily good TPR (equivalently, small FNR) and terrible TNR (equivalently, small FPR).</p>
<p>In fact, we can construct one trivially:</p>
<p><span class="math display">\[\hat{f}(\cdot) = 1\]</span></p>
<p>That is, the function that predicts <span class="math inline">\(1\)</span> <em>always</em>. This classifier has zero false negatives, because it has no negatives whatsoever, but it necessarily has many false positives.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>Conversely,</p>
<p><span class="math display">\[\hat{f}(\cdot) = 0\]</span></p>
<p>has no false positives, but many false negatives.</p>
<p>Clearly, we need a ‘combination’ metric that combines both degrees of freedom into a single score. Popular choices include:</p>
<ul>
<li>Accuracy: the fraction of correct predictions (<span class="math inline">\((n_{00}+n_{11})/n\)</span>)</li>
<li>Balanced Accuracy: <span class="math inline">\(\frac{\text{TPR} + \text{TNR}}{2}\)</span></li>
<li><span class="math inline">\(F_1\)</span> Score: <span class="math inline">\(2 *(1 - \text{FDR}) / (\text{TPR} - \text{FDR} +1)\)</span></li>
</ul>
<p>While these choices are popular, none of them are actually all that suitable for a real application. To properly evaluate a classifier, we need to know the real cost of false positives and false negatives, as well as the population base rates, and balance things accordingly.</p>
<p>For instance, if we are designing a ‘baseline’ medical diagnostic to be used as part of annual physicals, we need to think about what happens with false negatives and false positives.</p>
<ul>
<li>If we give a false positive, patients will undergo a better test that costs $1,000 but gives an accurate answer in all circumstances (a “gold standard”).</li>
<li>If we give a false negative, patients will leave a condition untreated until it becomes far worse, requiring expensive surgery costing $50,000.</li>
</ul>
<p>In this case, we might desire a classifier that minimizes <span class="math display">\[n_{10} + 50 n_{01}\]</span>, not any of the of the ‘standard’ metrics. Note also that the particular FPR, FNR of this classifier will depend on the rate of the condition in the population, so we can’t actually find the best procedure by looking at FPR, FNR in isolation.</p>
<p>While this <em>decision-theoretic</em> approach is optimal, it is often quite difficult to characterize in practice. In the example above, for instance, we made the choice to only minimize cost, without seeking to minimize suffering. (What if the untreated condition is <em>incredibly</em> painful? Should we intervene more often?) This sort of decision-making is ultimately very problem-specific and too often ignored in the academic literature. In practice, designing (and optimizing) the correct loss function is far more relevant to business outcomes than finding the best classifier to optimize an irrelevant cost function. procedure requires</p>
</section>
<section id="trade-off-of-recall-and-precision" class="level3">
<h3 class="anchored" data-anchor-id="trade-off-of-recall-and-precision">Trade-Off of Recall and Precision</h3>
<p>Our discussion of ‘trivial’ classifiers that focus on one metric while completely ignoring the other may remind you of the way this is typically solved in statistical testing procedures. We specify a maximum acceptable false positive rate (level or 1 - confidence) and then minimize the false negative rate subject to that constraint; in statistical speak, we seek a test with <em>maximal power</em>.</p>
<p>As we have seen with ridge and lasso regression, there is typically a ‘knob’ (hyperparameter) we can pick to tune a particular classifier. It is common to apply the classifier at all values of this knob, measure the TPR and TNR at all levels, and plot them in a trade-off curve. This curve is, for historical reasons, known as the receiver operating characteristic (ROC)<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> curve and it looks something like:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(yardstick)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Example from ?roc_curve</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">roc_curve</span>(two_class_example, truth, Class1) <span class="sc">%&gt;%</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">1</span> <span class="sc">-</span> specificity, <span class="at">y =</span> sensitivity)) <span class="sc">+</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>() <span class="sc">+</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">lty =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_equal</span>() <span class="sc">+</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="notes05_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Here we see that, for this particular classifier, increased specificity is associated with decreased sensitivity or, in the alternative terms, increased TNR is associated with decreased TPR. As illustrated by our example of constant predictors above, this is a quite typical trade-off.</p>
<p>Curves like this can be used in a few ways, none of which are fully satisfying:</p>
<ul>
<li>If we have two curves, we can plot their ROCs on the same set of axes. If one classifier is <em>uniformly</em> above the other, it is said to <em>dominate</em> the other and is better for all applications. Sadly, this is rarely the case.</li>
<li>If we have two curves and plot their ROCs, but the ROCs cross, we don’t have strong guidance on which model to prefer, but if one is <em>almost always</em> above the other, we will likely still use it.</li>
</ul>
<p>A commonly reported metric is the <em>area under the ROC curve</em> (AUC), which ranges from 0.0 to 1.0, with higher values being better. This is a bit unsatisfying compared to the decision theoretic analysis, but it is an improvement over some other metrics as it at least addresses the fact there is a tradeoff.</p>
<div class="callout-info" title="Pause for Reflection">
<p>What does an AUC less than 0.5 imply? If you get an AUC less than 0.5, what should you do? Why is AUC near 0 actually a good thing?</p>
</div>
<p>While the ROC is typically motivated by presence of a ‘tuning knob’, even methods like logistic regression (which have no obvious knobs) have an implicit knob we can choose to tune: the <em>classification threshold</em>. There is no law of nature that says that a predicted probability of 55% has to correspond to a prediction of the positive class. If false positives are very expensive, we may want to reduce the fraction of positives predicted and only predict the positive class when the estimated probability is over 80%. Similarly, if false negatives are very bad, we may want to predict positive even when the probability of a positive is in the 40% range: this is particularly common in medical contexts where the impact of a missed diagnosis is quite substantial, so doctors order extra diagnostic work ‘just to be sure’ even if the test does not strongly suggest a disease.</p>
</section>
<section id="scoring-functions" class="level3">
<h3 class="anchored" data-anchor-id="scoring-functions">Scoring Functions</h3>
<p><em>Scoring</em> functions are loss functions particularly suited for evaluation of probabilistic classifiers. Unlike our confusion-matrix set of metrics, it’s less clear how we should evaluate probabilistic classifiers.</p>
<p>It is clear that, if we predict something with 80% probability and it doesn’t happen, this is a ‘worse’ mistake than if we only had a 51% probability, but how can we measure this formally?</p>
<ul>
<li>Calibration and Tightness</li>
<li>Log Scores</li>
</ul>
</section>
</section>
<section id="types-of-classification-methods" class="level2">
<h2 class="anchored" data-anchor-id="types-of-classification-methods">Types of Classification Methods</h2>
<p>In this course, we will consider two main types of classifiers:</p>
<ol type="i">
<li><p>Generative classifiers, which attempt to jointly model <span class="math inline">\((\bX, \by)\)</span> and use probabilistic mathematics (mainly Bayes’ Rule) to infer <span class="math inline">\(\by | \bX\)</span> from the joint model.</p></li>
<li><p>Discriminative classifiers, which directly attempt to estimate the ‘boundary’ between the classes.</p></li>
</ol>
<p>As you will see, the terminology around these methods is <em>particularly</em> terrible.</p>
</section>
<section id="building-mutliclass-classifiers-from-binary-classifiers" class="level2">
<h2 class="anchored" data-anchor-id="building-mutliclass-classifiers-from-binary-classifiers">Building Mutliclass Classifiers from Binary Classifiers</h2>
<p>As we introduce methods, we will typically derive them for the binary classification task. If we want to apply them to the multiclass task, how can we extend them? It would be quite cumbersome if we needed <em>brand new</em> methods each time.</p>
<p>In general, there are two main strategies we might use:</p>
<ul>
<li>One vs Rest</li>
<li>Each vs Each</li>
</ul>
<p>For simplicity, assume we are predicting <span class="math inline">\(K\)</span> classes. In the “one-vs-rest” strategy, we will build <span class="math inline">\(K\)</span> binary classifiers, of the form:</p>
<ul>
<li>Class 1 vs Not Class 1 (<em>i.e.</em>, Class 2, 3, 4, <span class="math inline">\(\dots\)</span>, <span class="math inline">\(K\)</span>)</li>
<li>Class 2 vs Not Class 2 (<em>i.e.</em>, Class 1, 3, 4, <span class="math inline">\(\dots\)</span>, <span class="math inline">\(K\)</span>)</li>
<li><em>etc.</em></li>
<li>Class <span class="math inline">\(K\)</span> vs Not Class <span class="math inline">\(K\)</span> (<em>i.e.</em>, Class 1, 2, 3, <span class="math inline">\(\dots\)</span>, <span class="math inline">\(K-1\)</span>)</li>
</ul>
<p>To make an actual prediction, we take the <em>highest</em> score of each of these classifiers. <em>E.g.</em>, if <span class="math inline">\(K=3\)</span> for categories “Red”, “Green” and “Blue”, we might predict:</p>
<ul>
<li><span class="math inline">\(\mathbb{P}(\text{Red}) = 0.8\)</span> and <span class="math inline">\(\mathbb{P}(\text{Not Red}) = 0.2\)</span></li>
<li><span class="math inline">\(\mathbb{P}(\text{Green}) = 0.4\)</span> and <span class="math inline">\(\mathbb{P}(\text{Not Red}) = 0.6\)</span></li>
<li><span class="math inline">\(\mathbb{P}(\text{Blue}) = 0.2\)</span> and <span class="math inline">\(\mathbb{P}(\text{Not Red}) = 0.8\)</span></li>
</ul>
<p>Our final prediction would then be the maximizer, “Red.”</p>
<p>This strategy is relatively simple and intuitive, but for very large <span class="math inline">\(K\)</span>, the maximum can be far less than 50%, so it may feel a bit funny. (Why is this not an issue for <span class="math inline">\(K=2\)</span>?)</p>
<p>Conversely, in the “each vs each” (sometimes called “one vs one”) setting, we train <span class="math inline">\(\binom{K}{2} = K(K-1)/2\)</span> classifiers for every possible <em>pair</em> of classes. To get the prediction, we then take a ‘majority vote’ of the classifiers.</p>
<p>In our <span class="math inline">\(K=3\)</span> example above, we would have three classifiers:</p>
<ul>
<li>Red vs Blue, which we fit after throwing out the “Green” points</li>
<li>Red vs Green, which we fit after throwing out the “Blue” points</li>
<li>Green vs Blue, which we fit after throwing out the “Red” points</li>
</ul>
<p>If we make predictions for a single point, our binary classifications might be</p>
<ul>
<li>Red vs Blue: Red</li>
<li>Red vs Green: Red</li>
<li>Green vs Blue: Blue</li>
</ul>
<p>In this case, we would take a majority vote to get “Red” as our final prediction.</p>
<p>I find this strategy a bit counterintuitive, but it is sometimes faster than the one-vs-rest strategy since each individual model is fit to a subset of the entire data set.</p>
<p>Certain modern ML strategies, in particular deep neural networks, predict the probability of all <span class="math inline">\(K\)</span> classes from a single model. In this case, we typically select the single most probable class as our prediction.</p>
<p>In applications where there are multiple contenders and the difference between them is small, it is common to randomly select a class in proportion to its predicted probability. This strategy is one of the things that gives ChatGPT its randomness; it usually predicts the <em>most likely</em> next word, but sometimes it does something a little bit weird.)</p>
<p>Note that it is actually usually pretty hard to make a model that predicts a large set of probabilities simultaneously: in particular, it’s hard to get a vector that sums to one (like probabilities should). To address this, a <a href="https://en.wikipedia.org/wiki/Softmax_function">softmax</a> normalization is applied. This is essentially nothing more than i) making sure each predicted value is positive; and ii) dividing them all by the sum so they add to 1.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Consider, <em>e.g.</em>, predicting someone’s annual tax liability. <em>Technically</em>, this is <em>discrete</em> since tax liabilities are rounded to the nearest dollar, but functionally it may as well be continuous.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Even though it doesn’t make sense to average ordinal data, University administrators are <em>notorious</em> for averaging Likert data to evaluate faculty. This is a nigh-universal grievance of numerically-minded faculty, but getting universities to change their established procedures to something statistically reasonable is only slightly less impossible than drawing blood from a turnip.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>In this case, the FPR is exactly equal to the negative rate in the population.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Don’t confuse this with <em>Rate of Change</em>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/michael-weylandt\.com\/STA9890\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/michaelweylandt/STA9890/edit/main/notes/notes05.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/michaelweylandt/STA9890/blob/main/notes/notes05.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/michaelweylandt/STA9890/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>