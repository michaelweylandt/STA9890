{
  "hash": "c7bbfaed633c37b12971a9601918933f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"{{< var course.short >}} Research Report #{{< meta rr_num >}}: {{< meta rr_title >}}\"\nformat:\n  html:\n    code-link: true\nrr_num: \"02\"\nrr_title: \"Ensemble Learning Techniques for Fair Classification\"\nfilters: \n  - list-table\nfreeze: \"auto\"\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n### Key Dates\n\n- Released to Students: 2025\\-03\\-11\n- **Submission: 2025\\-04\\-18 11:45pm ET on Brightspace**\n\n*Estimated Time to Complete: 9 Hours*\n\n## Research Report #{{< meta rr_num >}}: {{< meta rr_title >}}\n\nIn this Research Report, you will explore concepts of *Machine Learning\nFairness* and see how ensemble learning techniques can be used to create a\n\"fair\" ensemble from \"unfair\" base learners.[^arxiv] Along the way, you will\n\ni)   Use a black-box optimizer to implement a form of regularized logistic\n     regression\nii)  Design and implement a custom ensemble learning strategy\niii) Implement and Assess Various ML Fairness Metrics\n\n[^arxiv]: This Research Report is adapted from my ongoing research collaboration\nwith Camille Little (Rice University) and Genevera Allen (Columbia University).\nA now-somewhat-dated manuscript describing our work in this space can be found\nonline at [ArXiv 2206.00074](https://arxiv.org/abs/2206.00074). \n\n### Project Skeleton\n\nYour report should be divided into three sections, covering the\nfollowing: \n\ni)   Background on ML Fairness\nii)  Computation - Implementing Regularized Logistic Regression with \n     `CVXR` or `cvxpy`\niii) Implementation and Assessment of the FairStacks Ensembling Method\n\nAt a minimum, these should include the following elements: \n\n- Background on ML Fairness\n  - Social background, including two examples of bias in automated decision\n    systems\n  - Overview of definitions used to measure ML Fairness\n  - Identification and import of a real data set on which we can evaluate\n    the proposed methodology. Be sure to describe both the \"raw\" data and the\n    fairness metric you are interested in. If there is relevant social context, \n    be sure to describe that as well. \n- Computation\n  - Introduction to the `CVX` optimization framework\n  - Implementation of the following classification methods as base learners\n    to be used in construction of the FairStacks ensemble:\n    - Naive Bayes (no `CVX`)\n    - Linear Discriminant Analysis (no `CVX`)\n    - Support Vector Machines (use `CVX`)\n    - Logistic Regression (use `CVX`): plain, ridge, and lasso variants\n    - Decision trees (you may use an existing implementation - use individual \n      tree(s) here, not a full random forest)\n- Implementation and Assessment of FairStacks\n  - Define the FairStacks Ensembling Problem, taking care to describe both\n    the choice of loss function (logistic loss)[^logloss], regularization and\n    any constraints used\n  - Implement the FairStacks Problem using `CVX`\n  - Implement a full model building (train-validation/ensembling-test split)\n    pipeline to implement FairStacks robustly\n  - Apply the FairStacks pipeline to your real data set and chosen fairness\n    metric\n  - Compute the fairness and accuracy obtained by the FairStacks ensemble and\n    compare it with the fairness and accuracy of the individual base learners.\n    Does FairStacks succeed in its goal of improving both accuracy and fairness?\n\n[^logloss]: In the FairStacks paper, we used OLS as a classification method for\nsomewhat technical reasons. For this Research Report, you should use logistic\nloss as your primary loss function. It may be an interesting extension to compare\nagainst OLS. \n\n### Additional Background\n\n#### ML Fairness\n\nAs ML systems continue to permate our society, increasing interest has been paid\nto their effects on society. ML systems are highly effective at replicating\nthe characteristics of their training data - both good (accuracy) and bad \n(bias).[^chatbot] The book BHN reviews this emerging area in some detail. \n\nFor our purposes, we can restrict our attention to 'fair classification', *i.e.*,\nmaking sure that ML systems treat different groups 'equally' (BHN §3). There are\nmany definitions of 'equally' that can be appropriate, depending on the problem. \nIn the simplest, *demographic parity*, the ML system should give the same fraction\nof positive (+1) labels to all demographic groups; this is the type of fairness\nembodied by phrases like \"looks like America\". We quantify this with measures \nlike *deviation from demographic parity*. If we divide our population into two\ngroups $\\mathcal{G}_1, \\mathcal{G}_2$, the deviation from demographic parity\nassociated with a classifier $f: \\mathbb{R}^p \\to \\{0, 1\\}$ is given by: \n\n$$\\text{DDP}(f) = \\left|\\frac{1}{|\\mathcal{G}_1|}\\sum_{i \\in \\mathcal{G}_1} f(\\mathbf{x}_i) - \\frac{1}{|\\mathcal{G}_2|}\\sum_{i \\in \\mathcal{G}_2} f(\\mathbf{x}_i)\\right| = \\left|\\mathbb{E}_{\\mathbf{x} \\sim \\mathcal{G}_1} f(\\mathbf{x}) - \\mathbb{E}_{\\mathbf{x} \\sim \\mathcal{G}_2} f(\\mathbf{x}) \\right|$$\n\nThe 2018 FAccT Tutorial [\"21 Fairness Definitions and Their Politics\"](https://fairmlbook.org/tutorial2.html) covers this and other fairnesss\nmetrics. For purposes of this project, you should consider the fairness metric\nthat is most appropriate to the social context surrounding your dataset of interest.\nNote that, if your interest is in a non-US data set, the relevant subgroups and\nlegal doctrines may be significantly different than those (implicitly) assumed by\nmost of the FairML literature. \n\n[^chatbot]: The earliest entries in the modern era of chatbots were marked by\nseveral flaws reflective their training data. Early iterations of the chat engine\nbuilt into the Bing search engine were often [rather overly-sexual and \nnot-so-subtly malicious](https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html),\nperhaps reflecting the darker corners of the internet on which it was trained.\n\n#### FairStacks\n\n[FairStacks](https://arxiv.org/abs/2206.00074) is a novel ensemble learning\nmethod which attempts to create a fair ensemble from a set of unfair base\nlearners. At the highest level, FairStacks generalizes the following idea: if\nApproach A is biased *against* a group and Approach B is biased *in favor of* \nthe same group, then Approach (A + B) will be approximately unbiased. \n\nTo put FairStacks into practice, we modify our basic ensembling procedure: in\nstandard ensemble learning, we create a \"model of models\", finding weights\n$\\hat{\\mathbf{w}}$ such that\n\n$$ \\hat{\\mathbf{w}} = \\text{arg min}_{\\mathbf{w}} \\frac{1}{n}\\sum_{i=1}^n \\text{Loss}\\left(\\mathbf{y}, \\sum_j w_j \\hat{f}_j(\\mathbf{x}_i)\\right) $$\n\nwhere the inner sum is taken over the base learners $\\{\\hat{f}_j\\}$. We add\n'fairness' in the form of a regularizer (penalty). If $\\hat{b}_j$ is the\nbias of base learner $\\hat{f}_j$, FairStacks solves\n\n\n$$ \\hat{\\mathbf{w}} = \\text{arg min}_{\\mathbf{w}} \\frac{1}{n}\\sum_{i=1}^n \\text{Loss}\\left(\\mathbf{y}, \\sum_j w_j \\hat{f}_j(\\mathbf{x}_i)\\right) + \\underbrace{\\lambda \\left|\\sum_j w_j \\hat{b}_j\\right|}_{\\text{Fairness Penalty}}$$\n\nBy setting $\\lambda$ large, we force the 'average bias' down to zero, resulting\nin a fairer ensemble. See the paper for more details.\n\n#### CVX\n\nThe `CVX` family of libraries attempt to make convex optimization easy and\naccesible to a wide range of users. Implementations of `CVX` can be found in:\n\n- Matlab: [the original `CVX`](https://cvxr.com/cvx/)\n- Python: [`cvxpy`](https://www.cvxpy.org/)\n- R: [`CVXR`](https://cvxr.rbind.io/)\n- Julia: [`Convex.jl`](https://jump.dev/Convex.jl/stable/)\n\nand more. While the details vary according to the host language, the essential\nstructure is unchanged. I demonstrate the use of `CVXR` here to implement\nLasso regression. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(CVXR)  # Load CVXR\nn <- 400       # Set up a moderately high-dimensional problem\np <- 1000\ns <- 5\nsigma <- 2\n\n# Lasso works best for IID Gaussian data\nX <- matrix(rnorm(n * p), \n            nrow=n, ncol=p)\n\n# 'True' coefficients are mainly sparse with 5 non-zero values\nbeta_star <- matrix(rep(0, p), ncol=1)\nbeta_star[1:s] <- 3\n\n# Generate observed response from OLS DGP\ny <- X %*% beta_star + rnorm(n, sd=sigma)\n\n## We are now ready to apply CVXR\n####  Also see discussion at\n####  https://www.cvxpy.org/examples/machine_learning/lasso_regression.html\n\nbeta <- Variable(p) # Create 'beta' as a CVX _variable_ to be optimized\n\n# Per theory, about the right level of regularization to be used here\nlambda  <- sigma * sqrt(s * log(p) / n) \nloss    <- 1/(2 * n) * sum((y - X %*% beta)^2) # MSE Loss\npenalty <- lambda * sum(abs(beta))\n\nobjective <- Problem(Minimize(loss + penalty))\nbeta_hat  <- solve(objective)$getValue(beta)\n```\n:::\n\n\n\nWe can see that this correctly finds the non-zero elements: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(beta_hat, \n     xlab=\"Coefficient Number\", \n     ylab=\"Lasso Estimate\", \n     main=\"CVX Lasso Solution\", \n     col=\"red4\", \n     pch=16)\n```\n\n::: {.cell-output-display}\n![](report02_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\nIf we look more closely, we see two important properties of the solution: \n\ni) Non-specialized solvers like `CVXR` cannot achieve *exact* zeros, \n   so it is useful to do a bit of post-processing (*e.g.*, `zapsmall()`).\n   \n   If we need _exact_ zeros, other approaches should be used\nii) The lasso solution exhibits _shrinkage_, as the estimate are\n    systematically smaller than the true values\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(beta_hat, n=10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               [,1]\n [1,]  2.186137e+00\n [2,]  2.337472e+00\n [3,]  2.225654e+00\n [4,]  2.238978e+00\n [5,]  2.257902e+00\n [6,] -1.595219e-21\n [7,]  1.525692e-21\n [8,] -3.301139e-21\n [9,] -5.077966e-22\n[10,]  2.632486e-21\n```\n\n\n:::\n:::\n\n\n\n`CVX` is never the *optimal* approach for a given problem, but it is an\nincredibly useful tool for prototyping and trying out interesting new\napproaches without putting in the effort to derive and implement a\nspecialized algorithm. (Tools like `tensorflow` and `pytorch` take this\nidea even further, but require significantly more effort to learn. If you\nare interested in working in ML after this course ends, they are a great\nplace to invest your time.)\n\nThe documentation for the `CVX` packages has several examples which will be\nof use for you. \n\n### Possible Topic(s) for Additional Research\n\n#### Algorithms for Regularized Logistic Regression\n\nFor this report, you are not required to fit the FairStacks problem \"by hand\"\nand can use `CVX` instead. While `CVX` is flexible and easy to use, it rarely\nperforms as efficiently as a hand-coded tailored algorithm. You may want to \nexplore the use of convex optimization algorithms for fitting logistic regression\nproblems generally and the FairStacks problem specifically. \n\nWhile the gradient descent method you used in [Research Report #01](./report01.html)\ncan be applied here, it is likely to be unbearably slow. You may achieve better\nperformance using a **Newton** or **Quadratic Approximation** approach. These\napproaches use a (second-order) Taylor expansion to approximate the objective\nfunction by a quadratic function; that quadratic function has a closed-form \nminimizer (essentially the OLS solution) which is used to update the iterate.[^gd]\nA new approximation is created at the new iterate, solved again, *etc.* See\nBV §9.5 for details. This approach is widely used to fit *generalized linear\nmodels* such as logistic regression. In the statistics literature, you may see\nit described as Iteratively Reweighted Least Squares or Fisher Scoring; see, \n*e.g.*, the output of `summary` on a `glm` fit in `R`.\n\n[^gd]: For this approach, you should use the matrix-analytic closed-form OLS\nsolution instead of using 'internal' gradient descent. The aim of Newton methods\nis to avoid gradient descent.\n\n#### Alternative Fair ML Proposals\n\nThe FairStacks approach is far from the only Fair ML proposal in the literature.\nIf this is a topic that interest you, you may want to compare FairStacks to other\nproposals and see which performs the best on your data set and which achieves\nan acceptable level of fairness. (Not all methods can achieve all levels of \nfairness). Even though FairStacks worked the best on the problems we considered, \nit may not be the best for your data set - there is no free lunch after all!\n\n#### Additional Randomization\n\nAs discussed in class, ensemble methods work best when the base learners exhibit\nrelatively low degrees of correlation. (If all base learners make the same\nprediction, it does not matter how they are weighted in the ensemble.) This\nis often particularly difficult to guarantee when applying powerful ML techniques\nto not-too-difficult prediction problems, as any technique worth knowing will\nperform reasonably well. In the FairStacks paper, we used a novel technique\ncalled *mini-patching*[^mp] to increase the variance of the base learner ensemble: \nmini-patching works by taking small subsets of both rows (observations) and \ncolumns (features) and fitting base learners to these subsets. We then fit\nthe mini-patched learners using the FairStacks ensembling approach. \n\nDoes this technique improve the performance of FairStacks on your data set? \nAre there other techniques you can use to create alternative / better base\nlearners to use in your ensemble?\n\n[^mp]: Mini-**P**atching is related to, but should not be confused with the more\ncommon technique of Mini-**B**atching. \n\n### Submission Instructions\n\nSubmit your research report as a PDF of 6-8 pages on Brightspace.[^pdf]\nYour submission should include all *essential* code, *e.g.*, code\nused to fit models or to perform simulations, but may omit\n*incidental* code, *e.g.* code used to create figures or import\ndata. \n\nYou are **required** to implement ML methods by hand; use of 'built-in'\nML functionality is disallowed unless authorized by instructor. You may use\nbuilt-in linear algebra subroutines and are not required to, *e.g.*, implement\nmatrix multiplication from scratch. While you must use your own implementation\nof ML methods, it is smart to compare against existing 'reference' implementations.\n\nYour report should be in the style of a technical \"blog post\", accessible\nto someone who is just getting into Machine Learning but has solid\nbackground in the prerequisite subjects (*e.g.*, you on the day before\nthis class started). Make sure to (rigorously) define and prove all\nresults used. You should also cite relevant authoritative resources, \n*e.g.*, the recommended textbooks, where appropriate. \n\nEach student must submit an individual and independently written report, but you\nare encouraged to work together with your peers to understand methods, design\nsimulations, review relevant literature, *etc.* I strongly recommend having a\nclassmate [\"red-team\"](https://en.wikipedia.org/wiki/Red_team) your report\nbefore submission to find unclear writing, sub-standard figures and tables, \nunconvincing simulations, incorrect  code, *etc.* \n\n[^pdf]: If you wish to use an alternate submission format to allow\ninteractive and/or animated elements, please seek pre-approval from\nthe instructor. \n\n### Grading \n\nYour submission will be evaluated *holistically* and graded out of 100\npoints. The following rubric will guide this holistic evaluation, but\nthe instructor may deviate as necessary to accurately grade the final\nsubmission. \n\n::: {.list-table width=\"1,1,1,1,1,1\" aligns=\"c,c,c,c,c,c\" header-rows=1 .hover}\n\n * - Report Element\n   - Excellent. <br> \"A-\" to \"A\" (`90% to 100%`)\n   - Great. <br> \"B-\" to \"B+\" (`80% to 89%`)\n   - Average. <br> \"C\" to \"C+\" (`73% to 79%`)\n   - Poor. <br> \"D\" to \"C-\" (`60% to 72%`)\n   - Failure. <br> \"F\" (`0% to 59%`)\n   \n * - Presentation (15%)\n   - Report has excellent formatting, with particularly effective \n     tables and figures. Tables and Figures are \"publication-quality\"\n     and clearly and succinctly support claims made in the body text.\n   - Report has strong formatting; tables and figures make their\n     intended points, but do not do so optimally. \n   - Formatting is average; tables and figures do not clearly support\n     arguments made in the text and/or are not \"publication quality\"\n   - Poor formatting distracts from substance of report. Tables and\n     Figures exhibit significant deficiencies in formatting.  \n   - Formatting prohibits or significantly impairs reader understanding.\n \n * - Project Skeleton (15%)\n   - Report includes all required elements and goes significantly deeper\n     than required by the project skeleton in a manner that provides \n     additional insights. \n     \n     Mathematical definitions and proofs are clearly stated. \n     \n   - Report includes all required elements and dives deeper into the\n     topic, but does not generate additional insights. (*E.g.*,\n     additional simulations showing the same phenomena)\n     \n     Mathematical definitions and proofs are correctly stated, but \n     clarity could be improved. \n     \n   - Report includes all required elements. \n   \n     Mathematical definitions and proofs are essentially correct,\n     but difficult to understand and/or contain trivial errors.\n   \n   - Report does not include all required elements, but is still\n     able to capture key points. \n     \n     Mathematical definitions and proofs contain significant, but\n     non-fatal, errors. \n   - Report fails to adequately address the topic. \n   \n     Mathematical definitions and proofs are fundamentally incorrect. \n \n * - Algorithms and Computational Efficiency (20%)\n   - Report implements all methods efficiently with high-quality,\n     well-formatted and performant code. \n   - Report implements all methods efficiently with acceptable\n     code quality. \n   - Report implements all methods, but does not do so efficiently\n     and/or with substandard code. \n   - Report uses built-in methods instead of implementing methods\n     from scratch\n   - Code does not appear to run properly / insufficient code submitted. \n \n * - Methodological Aspects and Simulation Design(20%)\n   - Methods are accurately and correctly implemented in a robust / bullet-proof\n     manner, designed to responsibly check for and address possible modes of\n     failure. Simulations clearly and efficiently support all claims. \n   - Methods are accurately and correctly implemented, but are not robust to\n     failure. Simulations clearly and efficiently support all claims. \n   - Methods are implemented with minor harmless errors and/or poor validation.\n     Simulations do not fully support claims. \n   - Methods are implemented with significant errors leading to incorrect results. \n   \n     Simulations do not give sufficient support for key claims.\n   - Methods are not correctly implemented. Simulations do not support claims.\n \n * - Communication and Writing (20%)\n   - Report exhibits excellent written communication, making all points\n     exceptionally clearly and at the level of a quality academic\n     publication. Code, results, and text are skillfully woven together.\n   - Report exhibits great written communication, all points are made\n     clearly without notable grammatical errors. Code, results, and\n     text are neatly tied together. \n   - Report exhibits solid written communication, key points are made \n     understandably and any grammatical errors do not impair\n     understanding. Code, results, and text could be better integrated, \n     but it is clear which elements relate. \n   - Written communication is below standard: points are not always\n     understandable and/or grammatical errors actively distract from\n     content. Code, results, and text are not actively integrated, but\n     are generally located 'near' each other in a semi-systematic fashion.\n   - Written communication is far below standard, possibly bordering\n     on unintelligible. Large blocks of code are shown without any\n     relevant results or text. \n \n * - Contextualization (10%)\n   - Report draws on relevant, modern research literature to give context\n     to its findings and to broaden its scope. \n   - Report draws on standard textbooks and/or classical research literature\n     to give context to its findings and to broaden its scope. \n   - Report cites textbooks to give context, but does not take a 'big picture' \n     view. \n   - Report gives appropriate context, but lacks citations. \n   - Report gives limited, insufficient context.\n\n:::\n\n------------------------------------------------------------------------\n\nThis work ©2025 by [Michael Weylandt](https://michael-weylandt.com) is licensed\nunder a [Creative Commons BY-NC-SA \n4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en) license.\n![](http://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png){width=\"10%\"}\n",
    "supporting": [
      "report02_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}